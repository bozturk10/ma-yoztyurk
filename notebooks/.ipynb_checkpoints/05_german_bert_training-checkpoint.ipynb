{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54b859f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa1bb618",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "import pandas as pd\n",
    "from src.data.process_data import coding_list_dict,process_open_ended,process_wave_data\n",
    "from src.data.read_data import load_raw_survey_data\n",
    "from src.paths import PROMPT_DIR,RAW_DATA_DIR,MODELS_DIR,CODING_DIR\n",
    "from src.utils import format_prompt\n",
    "from src.bert.training import prepare_dataset,train_bert_model\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv('../experiment_berk.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a0a01ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.bert.training import prepare_open_ended_df, init_model_and_tokenizer, compute_metrics\n",
    "import os\n",
    "\n",
    "wave_number = 21\n",
    "train_val_test_df,id2label = prepare_open_ended_df(wave_number)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a47b1fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training model with num_labels: 53\n",
      "id2label: {0: 'Corona-Pandemie', 1: 'Werte, politische Kultur und Gesellschaftskritik', 2: 'Arbeitsmarktpolitik', 3: 'Politische Strukturen und Prozesse', 4: 'Migration und Integration', 5: 'Wirtschaftspolitik', 6: 'Klimapolitik', 7: 'Rente und Demographischer Wandel', 8: 'Gesundheitspolitik', 9: 'Armut', 10: 'Soziale Gerechtigkeit', 11: 'Radikalisierung und Extremismus', 12: 'Pflege', 13: 'Sozialpolitik', 14: 'Steuerpolitik', 15: 'Parteienkritik spezifisch', 16: 'Umweltpolitik', 17: 'Politiker:innenkritik allgemein', 18: 'Wohnungspolitik', 19: 'Sonstiges', 20: 'Bildungspolitik', 21: 'Innere Sicherheit', 22: 'Arbeitslosigkeit und Grundsicherung', 23: 'Medien', 24: 'Finanzpolitik', 25: 'Preisniveau', 26: 'Familienpolitik', 27: 'Ostdeutschland', 28: 'Digitale Infrastruktur', 29: 'Lobbyismus', 30: 'Recht und Justiz', 31: 'Parteienkritik allgemein', 32: 'Kriminalität und Gewalt', 33: 'Energiepolitik', 34: 'Wahlkampf und Regierungsbildung', 35: 'Außenpolitik', 36: 'Lohnpolitik', 37: 'Korruption', 38: 'Demokratie', 39: 'Schulpolitik', 40: 'Bürokratie', 41: 'Gleichstellung', 42: 'Terrorismus', 43: 'Europa und Europäische Union', 44: 'Politikverdrossenheit', 45: 'Internationale Konflikte und Frieden', 46: 'Politiker:innenkritik spezifisch', 47: 'Infrastruktur', 48: 'Populismus', 49: '(Beziehungen Deutschlands zu) Russland', 50: 'Verkehrspolitik', 51: 'Krieg in der Ukraine', 52: 'Naturkatastrophen'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-german-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Map: 100%|██████████| 12431/12431 [00:04<00:00, 2875.88 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['text', 'label', '__index_level_0__', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "        num_rows: 9944\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['text', 'label', '__index_level_0__', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "        num_rows: 1244\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['text', 'label', '__index_level_0__', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
      "        num_rows: 1243\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model_path = os.path.join(MODELS_DIR, 'fine_tuned_german_bert_20240411_194414')\n",
    "tokenizer, model = init_model_and_tokenizer(id2label)\n",
    "splits=prepare_dataset(train_val_test_df,tokenizer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca06c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"WANDB_PROJECT\"]=\"thesis\"\n",
    "os.environ[\"WORLD_SIZE\"] = \"1\"  # Number of processes\n",
    "os.environ[\"MASTER_ADDR\"] = \"localhost\"\n",
    "os.environ[\"MASTER_PORT\"] = \"12345\"\n",
    "train_bert_model(model, tokenizer, splits,report_to=\"wandb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9664f6c6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'classifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m pred_list\u001b[38;5;241m=\u001b[39m[]\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, row \u001b[38;5;129;01min\u001b[39;00m df_test\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m----> 7\u001b[0m     pred_list\u001b[38;5;241m.\u001b[39mappend(\u001b[43mclassifier\u001b[49m\u001b[38;5;241m.\u001b[39mprocess_llm_output( \u001b[38;5;28;01mNone\u001b[39;00m, predict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,text\u001b[38;5;241m=\u001b[39mrow[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m'\u001b[39m])[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredicted_class\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      8\u001b[0m df_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpred\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39mpred_list\n\u001b[1;32m      9\u001b[0m df_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39mdf_test\u001b[38;5;241m.\u001b[39mlabel\u001b[38;5;241m.\u001b[39mmap(id2label)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'classifier' is not defined"
     ]
    }
   ],
   "source": [
    "#model evaluation on test set, \n",
    "# splits['test'].to_pandas()[['text','label']]\n",
    "#iterate over and add prediction col for each row\n",
    "df_test=  splits['test'].to_pandas()[['text','label']]\n",
    "pred_list=[]\n",
    "for idx, row in df_test.iterrows():\n",
    "    pred_list.append(classifier.process_llm_output( None, predict=True,text=row['text'])['predicted_class'])\n",
    "df_test['pred']=pred_list\n",
    "df_test['label']=df_test.label.map(id2label)\n",
    "import evaluate\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "precision = evaluate.load(\"precision\")\n",
    "recall = evaluate.load(\"recall\")\n",
    "f1 = evaluate.load(\"f1\")\n",
    "#get accuracy and f1 from 2 list of strings\n",
    "def get_accuracy_f1(predictions, labels):\n",
    "    #map the string labels to integers\n",
    "    label2id = {label: idx for idx, label in enumerate(set(labels))}\n",
    "    labels = [label2id[label] for label in labels]\n",
    "    predictions = [label2id[pred] for pred in predictions]\n",
    "    acc = accuracy.compute(predictions=predictions, references=labels)\n",
    "    f1_score = f1.compute(predictions=predictions, references=labels)\n",
    "    return acc['accuracy'], f1_score['f1']\n",
    "\n",
    "#get accuracy and f1 from 2 list of strings\n",
    "def get_accuracy_f1(predictions, labels):\n",
    "    #map the string labels to integers\n",
    "    label2id = {label: idx for idx, label in enumerate(set(labels).union(predictions)) }\n",
    "    labels = [label2id[label] for label in labels]\n",
    "    predictions = [label2id[pred] for pred in predictions]\n",
    "    acc = accuracy.compute(predictions=predictions, references=labels)\n",
    "    f1_score = f1.compute(predictions=predictions, references=labels,average='weighted')\n",
    "    return acc['accuracy'], f1_score['f1']\n",
    "    \n",
    "get_accuracy_f1(df_test['pred'].tolist(), df_test['label'].tolist())\n",
    "\n",
    "df_test=  splits['test'].to_pandas()[['text','label']]\n",
    "\n",
    "for idx, row in df_test.iterrows():\n",
    "    df_test.loc[idx, 'prediction'] = clf(row['text'])[0]['label']\n",
    "from evaluate import evaluator\n",
    "from src.bert.classify import BertClassifier\n",
    "\n",
    "os.environ['HUGGINGFACE_HUB_CACHE'] = '/dss/dssmcmlfs01/pr74ze/pr74ze-dss-0001/ra46lup2/.cache/huggingface/hub'\n",
    "model_name='fine_tuned_german_bert_20240411_194414'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "classifier = BertClassifier(model_name, device)\n",
    "tokenizer, model = classifier.load_trained_model_and_tokenizer()\n",
    "\n",
    "from transformers import pipeline\n",
    "clf = pipeline(\"text-classification\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "task_evaluator = evaluator(\"text-classification\")\n",
    "\n",
    "\n",
    "eval_results = task_evaluator.compute(\n",
    "    model_or_pipeline=clf,\n",
    "    data=splits['test'],\n",
    "    label_mapping={v: int(k) for k, v in classifier.config['id2label'].items()}\n",
    ")\n",
    "\n",
    "# splits['test'].to_pandas()[['text','label']]\n",
    "#iterate over and add prediction col for each row\n",
    "df_test=  splits['test'].to_pandas()[['text','label']]\n",
    "\n",
    "for idx, row in df_test.iterrows():\n",
    "    df_test.loc[idx, 'prediction'] = clf(row['text'])[0]['label']\n",
    "print('(0.8650442477876106, 0.848446433665514)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0144367",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
