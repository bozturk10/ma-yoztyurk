{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5754c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef3d192",
   "metadata": {},
   "outputs": [],
   "source": [
    "/dss/dsshome1/0F/ra46lup2/miniconda3/envs/llm/bin/python /dss/dsshome1/0F/ra46lup2/ma-yoztyurk/src/bert_classify.py /dss/dsshome1/0F/ra46lup2/ma-yoztyurk/results/mistralai-Mixtral-8x7B-Instruct-v0.1_12_1712772173"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3249d164",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "import pandas as pd\n",
    "from src.data.process_data import coding_list_dict,process_open_ended,process_wave_data\n",
    "from src.data.read_data import load_raw_survey_data\n",
    "from src.paths import PROMPT_DIR,RAW_DATA_DIR,MODELS_DIR,CODING_DIR\n",
    "from src.utils import format_prompt\n",
    "from src.bert.training import prepare_dataset,train_bert_model\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv('../experiment_berk.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d742e947",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.bert.training import prepare_open_ended_df, init_model_and_tokenizer, compute_metrics\n",
    "import os\n",
    "\n",
    "wave_number = 21\n",
    "train_val_test_df,id2label = prepare_open_ended_df(wave_number)\n",
    "tokenizer, model = init_model_and_tokenizer(id2label)\n",
    "splits=prepare_dataset(train_val_test_df,tokenizer)\n",
    "\n",
    "train_bert_model(model, tokenizer, splits,report_to=\"wandb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758d202c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb9c494",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"WANDB_PROJECT\"]=\"thesis\"\n",
    "os.environ[\"WORLD_SIZE\"] = \"1\"  # Number of processes\n",
    "os.environ[\"MASTER_ADDR\"] = \"localhost\"\n",
    "os.environ[\"MASTER_PORT\"] = \"12345\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1a676c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = os.path.join(MODELS_DIR, 'fine_tuned_german_bert_20240411_194414')\n",
    "from src.bert.classify import BertClassifier\n",
    "device= 'cuda'\n",
    "classifier = BertClassifier(model_path, device)\n",
    "#model evaluation on test set, \n",
    "# splits['test'].to_pandas()[['text','label']]\n",
    "#iterate over and add prediction col for each row\n",
    "df_test=  splits['test'].to_pandas()[['text','label']]\n",
    "pred_list=[]\n",
    "for idx, row in df_test.iterrows():\n",
    "    pred_list.append(classifier.process_llm_output( None, predict=True,text=row['text'])['predicted_class'])\n",
    "df_test['pred']=pred_list\n",
    "df_test['label']=df_test.label.map(id2label)\n",
    "import evaluate\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "precision = evaluate.load(\"precision\")\n",
    "recall = evaluate.load(\"recall\")\n",
    "f1 = evaluate.load(\"f1\")\n",
    "#get accuracy and f1 from 2 list of strings\n",
    "def get_accuracy_f1(predictions, labels):\n",
    "    #map the string labels to integers\n",
    "    label2id = {label: idx for idx, label in enumerate(set(labels))}\n",
    "    labels = [label2id[label] for label in labels]\n",
    "    predictions = [label2id[pred] for pred in predictions]\n",
    "    acc = accuracy.compute(predictions=predictions, references=labels)\n",
    "    f1_score = f1.compute(predictions=predictions, references=labels)\n",
    "    return acc['accuracy'], f1_score['f1']\n",
    "\n",
    "#get accuracy and f1 from 2 list of strings\n",
    "def get_accuracy_f1(predictions, labels):\n",
    "    #map the string labels to integers\n",
    "    label2id = {label: idx for idx, label in enumerate(set(labels).union(predictions)) }\n",
    "    labels = [label2id[label] for label in labels]\n",
    "    predictions = [label2id[pred] for pred in predictions]\n",
    "    acc = accuracy.compute(predictions=predictions, references=labels)\n",
    "    f1_score = f1.compute(predictions=predictions, references=labels,average='weighted')\n",
    "    return acc['accuracy'], f1_score['f1']\n",
    "    \n",
    "get_accuracy_f1(df_test['pred'].tolist(), df_test['label'].tolist())\n",
    "\n",
    "df_test=  splits['test'].to_pandas()[['text','label']]\n",
    "\n",
    "for idx, row in df_test.iterrows():\n",
    "    df_test.loc[idx, 'prediction'] = clf(row['text'])[0]['label']\n",
    "from evaluate import evaluator\n",
    "from src.bert.classify import BertClassifier\n",
    "\n",
    "os.environ['HUGGINGFACE_HUB_CACHE'] = '/dss/dssmcmlfs01/pr74ze/pr74ze-dss-0001/ra46lup2/.cache/huggingface/hub'\n",
    "model_name='fine_tuned_german_bert_20240411_194414'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "classifier = BertClassifier(model_name, device)\n",
    "tokenizer, model = classifier.load_trained_model_and_tokenizer()\n",
    "\n",
    "from transformers import pipeline\n",
    "clf = pipeline(\"text-classification\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "task_evaluator = evaluator(\"text-classification\")\n",
    "\n",
    "\n",
    "eval_results = task_evaluator.compute(\n",
    "    model_or_pipeline=clf,\n",
    "    data=splits['test'],\n",
    "    label_mapping={v: int(k) for k, v in classifier.config['id2label'].items()}\n",
    ")\n",
    "\n",
    "# splits['test'].to_pandas()[['text','label']]\n",
    "#iterate over and add prediction col for each row\n",
    "df_test=  splits['test'].to_pandas()[['text','label']]\n",
    "\n",
    "for idx, row in df_test.iterrows():\n",
    "    df_test.loc[idx, 'prediction'] = clf(row['text'])[0]['label']\n",
    "print('(0.8650442477876106, 0.848446433665514)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea320e5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
