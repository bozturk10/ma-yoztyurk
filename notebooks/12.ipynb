{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import wandb\n",
    "import os \n",
    "import pandas as pd\n",
    "from src.paths import CODING_DIR, LOGS_DIR\n",
    "from src.bert.metrics import define_metrics, get_compute_metrics_function\n",
    "from src.bert.data_prep import (\n",
    "    get_annotated_answers, get_answer_df, get_classid2trainid,\n",
    "    get_label2str_dict, prepare_test_dataset, prepare_train_dataset,\n",
    "    split_llm_train_test, split_train_test_df\n",
    ")\n",
    "from src.bert.bert_classifier import BertClassifier\n",
    "class_mode='coarse'\n",
    "i=12\n",
    "answer_df = get_answer_df(class_mode,drop_duplicates=True)\n",
    "train_df, test_df = split_train_test_df(answer_df, i)\n",
    "llm_answer_df = get_annotated_answers()\n",
    "llm_train_df, llm_test_df = split_llm_train_test(llm_answer_df, test_size=0.2)\n",
    "train_df_combined = pd.concat([train_df, llm_train_df])\n",
    "test_df_combined = pd.concat([test_df, llm_test_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_df2 = get_answer_df(class_mode,drop_duplicates=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_df2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_df['labels_count']= answer_df['labels_list'].apply(lambda x: len(x))\n",
    "\n",
    "llm_answer_df['labels_count']= llm_answer_df['labels_list'].apply(lambda x: len(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_df['labels_count'].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_labels_matrix=  pd.DataFrame(answer_df['labels'].tolist(), columns=label_names )\n",
    "survey_labels_matrix.drop(list(survey_labels_matrix.filter(regex='LLM refusal')), axis=1, inplace=True)\n",
    "survey_labels_matrix.sum(axis=0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_labels_matrix.sum(axis=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "survey_labels_matrix.sum(axis=0)#.divide(survey_labels_matrix.sum(axis=0).sum())#.value_counts(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_labels_matrix.sum(axis=0)#.divide(llm_labels_matrix.sum(axis=0).sum())#.value_counts(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_labels_matrix=  pd.DataFrame(llm_answer_df['labels'].tolist(), columns=label_names )\n",
    "llm_labels_matrix.drop(list(llm_labels_matrix.filter(regex='LLM refusal')), axis=1, inplace=True)\n",
    "llm_labels_matrix.sum(axis=0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src\n",
    "import numpy as np\n",
    "from src.paths import MODELS_DIR, OUTPUTS_DIR\n",
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from src.data.process_data import process_open_ended, process_wave_data,process_open_ended\n",
    "from src.data.read_data import load_raw_survey_data, read_stata_file\n",
    "from src.paths import CODING_DIR, GLES_DIR, PROCESSED_DATA_DIR, ANNOTATED_GENERATIONS_DIR,RAW_DATA_DIR\n",
    "from src.utils import get_lang\n",
    "from src.paths import RESULTS_DIR\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "\n",
    "classid2trainid = {int(classname):idx  for idx, classname in enumerate(sorted(pd.read_csv(os.path.join(CODING_DIR,'map.csv')).upperclass_id.unique())) }\n",
    "df_lookup= pd.read_csv(os.path.join(CODING_DIR,'map.csv'))\n",
    "label2str= dict(zip(df_lookup.upperclass_id,df_lookup.upperclass_name))\n",
    "label_names= [label2str[i] for i in range(0,len(label2str)) ]\n",
    "\n",
    "labels_16= [label_name for label_name in label_names if label_name!='LLM refusal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_df.groupby('wave')['labels_count'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.analysis.ablationExperiment.utils import get_ablationExperiment_data\n",
    "survey_labels_dict,llm_labels_dict,survey_population_df,survey_group_pmf,llm_population_df,llm_group_pmf=get_ablationExperiment_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from src.data.process_data import process_open_ended, process_wave_data,process_open_ended\n",
    "from src.data.read_data import load_raw_survey_data, read_stata_file\n",
    "\n",
    "wave_number=12\n",
    "wave_df, wave_open_ended_df, df_coding_840s = load_raw_survey_data(wave_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coding_840s= df_coding_840s.filter(like='840_c', axis=1)\n",
    "import numpy as np\n",
    "#replace all cells with nan if it contains str '-'\n",
    "for m in minus_elts:\n",
    "    df_coding_840s = df_coding_840s.replace(m,np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10,22):\n",
    "    a= df_coding_840s[[f'kp{i}_840_c1',f'kp{i}_840_c2']].dropna(subset=[f'kp{i}_840_c1']).isna().mean()\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minus_elts= [ x  for x in df_coding_840s.kp10_840_c3.unique() if x<0 ]\n",
    "minus_elts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_df.kpx_840_c2.value_counts(1)\n",
    "answer_df.kpx_840_c10.value_counts(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
